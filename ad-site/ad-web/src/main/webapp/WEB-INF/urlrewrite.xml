<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE urlrewrite PUBLIC "-//tuckey.org//DTD UrlRewrite 4.0//EN"
        "http://www.tuckey.org/res/dtds/urlrewrite4.0.dtd">

<!-- Configuration file for UrlRewriteFilter http://www.tuckey.org/urlrewrite/ -->

<urlrewrite use-query-string="true">
	<rule>
		<name>Base googlebot</name>
		<condition name="user-agent">googlebot</condition>
		<from>^/$</from>
		<to type="forward" context="web">/pages/current/glowna/page_1.html</to>
	</rule>

	<rule>
		<name>Facebook bot</name>
		<condition name="user-agent">facebookExternalHit/1.1</condition>
		<from>^/$</from>
		<to type="forward" context="web">/pages/current/glowna/page_1.html</to>
	</rule>
	<rule>
		<name>Robots check</name>
		<from>^/\?_escaped_fragment_=(.*)\/([0-9]*)\/.*$</from>
		<to type="forward" context="web">/pages/current$1/$2.html?</to>
	</rule>


		<rule>
		<name>Robots check page</name>
		<from>^/\?_escaped_fragment_=(.*)\?.*page=([0-9]+).*$</from>
		<to type="forward" context="web">/pages/current$1/page_$2.html</to>
	</rule>
	<rule>
		<name>Robots check single</name>
		<from>^/\?_escaped_fragment_=(.*)$</from>
		<to type="forward" context="web">/pages/current$1/page_1.html?</to>
	</rule>
	<rule>
		<name>Robots</name>
		<from>^/robots.txt$</from>
		<to type="forward">/resources/web/robots.txt</to>
	</rule>
</urlrewrite>
